{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# Interactive widgets\n",
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now you can import the module\n",
    "from src.utils import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_SIZE = (224, 224)  # Image size (height, width)\n",
    "BATCH_SIZE = 32  # Batch size\n",
    "\n",
    "# Example Usage\n",
    "train_dir = \"../data/processed/train/\"\n",
    "val_dir = \"../data/processed/val/\"\n",
    "test_dir = \"../data/processed/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_jsonl(jsonl_path):\n",
    "    \"\"\"\n",
    "    Parse a JSONL file and yield image paths and labels.\n",
    "    \"\"\"\n",
    "    with open(jsonl_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            yield item[\"image\"], item[\"label\"]\n",
    "\n",
    "\n",
    "def load_datasets_from_directory(data_dir, batch_size=BATCH_SIZE, img_size=IMG_SIZE):\n",
    "    \"\"\"\n",
    "    Create a combined tf.data.Dataset from JSONL files in a directory.\n",
    "    Args:\n",
    "        data_dir (str): Directory containing JSONL files for train, val, or test splits.\n",
    "        batch_size (int): Batch size for the dataset.\n",
    "        img_size (tuple): Target size for images (height, width).\n",
    "    Returns:\n",
    "        tf.data.Dataset: Combined TensorFlow dataset.\n",
    "    \"\"\"\n",
    "    # Collect all JSONL files in the directory\n",
    "    jsonl_files = [\n",
    "        os.path.join(data_dir, fname)\n",
    "        for fname in os.listdir(data_dir)\n",
    "        if fname.endswith(\".jsonl\")\n",
    "    ]\n",
    "\n",
    "    # Helper function to load and parse one JSONL file\n",
    "    def load_single_jsonl(jsonl_path):\n",
    "        \"\"\"\n",
    "        Create a tf.data.Dataset from a single JSONL file.\n",
    "        \"\"\"\n",
    "\n",
    "        def generator():\n",
    "            # Parse JSONL into image paths and labels\n",
    "            with open(jsonl_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    item = json.loads(line)\n",
    "                    yield item[\"image\"], item[\"label\"]\n",
    "\n",
    "        # Create a dataset for this JSONL file\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generator, output_types=(tf.string, tf.int32), output_shapes=((), ())\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "    # Combine all datasets using flat_map\n",
    "    combined_dataset = None\n",
    "    for jsonl_path in jsonl_files:\n",
    "        single_dataset = load_single_jsonl(jsonl_path)\n",
    "        combined_dataset = (\n",
    "            single_dataset\n",
    "            if combined_dataset is None\n",
    "            else combined_dataset.concatenate(single_dataset)\n",
    "        )\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    def preprocess(image_path, label):\n",
    "        # Load and decode image\n",
    "        try:\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.image.decode_png(image, channels=3)\n",
    "        except tf.errors.NotFoundError:\n",
    "            print(f\"File not found: {image_path.numpy().decode('utf-8')}\")\n",
    "            return None, None\n",
    "\n",
    "        # Resize\n",
    "        image = tf.image.resize(image, img_size)\n",
    "        return image, label\n",
    "\n",
    "    # Apply preprocessing, batching, and shuffling\n",
    "    combined_dataset = (\n",
    "        combined_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .shuffle(buffer_size=1000)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    return combined_dataset\n",
    "\n",
    "\n",
    "train_dataset = load_datasets_from_directory(train_dir)\n",
    "# Check the type\n",
    "dataset_type = type(train_dataset)\n",
    "print(\n",
    "    f\"train_dataset inherits from tf.data.Dataset: {issubclass(dataset_type, tf.data.Dataset)}\"\n",
    ")\n",
    "\n",
    "val_dataset = load_datasets_from_directory(val_dir)\n",
    "# Check the type\n",
    "dataset_type = type(val_dataset)\n",
    "print(\n",
    "    f\"val_dataset inherits from tf.data.Dataset: {issubclass(dataset_type, tf.data.Dataset)}\"\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = load_datasets_from_directory(test_dir)\n",
    "\n",
    "# Check the type\n",
    "dataset_type = type(test_dataset)\n",
    "print(\n",
    "    f\"test_dataset inherits from tf.data.Dataset: {issubclass(dataset_type, tf.data.Dataset)}\"\n",
    ")\n",
    "\n",
    "# Example: Inspect a batch\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Batch of images shape: {images.shape}\")\n",
    "    print(f\"Batch of labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_image_dataset(directory, img_size=IMG_SIZE, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Load a custom dataset of images organized by 'charts' and 'non_charts' subdirectories.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing images organized in subdirectories by label.\n",
    "        img_size (tuple): Target size for images (height, width).\n",
    "        batch_size (int): Number of images per batch.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: A TensorFlow dataset containing images and their labels.\n",
    "        class_names (list): List of class names inferred from subdirectory names.\n",
    "    \"\"\"\n",
    "    # Load dataset with labels inferred from directory structure\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory,\n",
    "        labels=\"inferred\",  # Infer labels from subdirectory names\n",
    "        label_mode=\"int\",  # Return integer labels\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Extract class names before transformations\n",
    "    class_names = dataset.class_names\n",
    "\n",
    "    return dataset, class_names\n",
    "\n",
    "\n",
    "# Use it\n",
    "custom_train_dir = \"../data/processed/train\"\n",
    "custom_train_dataset, class_names = load_custom_image_dataset(custom_train_dir)\n",
    "\n",
    "custom_val_dir = \"../data/processed/val\"\n",
    "custom_val_dataset, _ = load_custom_image_dataset(custom_val_dir)\n",
    "\n",
    "# Check the type\n",
    "dataset_type = type(custom_train_dataset)\n",
    "print(\n",
    "    f\"custom_train_dataset inherits from tf.data.Dataset: {issubclass(dataset_type, tf.data.Dataset)}\"\n",
    ")\n",
    "\n",
    "# Check the type\n",
    "dataset_type = type(custom_val_dataset)\n",
    "print(\n",
    "    f\"custom_val_dataset inherits from tf.data.Dataset: {issubclass(dataset_type, tf.data.Dataset)}\"\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Class names: {class_names}\")  # Output: ['charts', 'non_charts']\n",
    "\n",
    "# Inspect the dataset\n",
    "for images, labels in custom_train_dataset.take(1):\n",
    "    print(f\"Batch of images shape: {images.shape}\")\n",
    "    print(f\"Batch of labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.concatenate(custom_train_dataset)\n",
    "val_dataset = val_dataset.concatenate(custom_val_dataset)\n",
    "\n",
    "# Example: Inspect a batch\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Batch of images shape: {images.shape}\")\n",
    "    print(f\"Batch of labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_dataset.take(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch from the dataset\n",
    "image_batch, label_batch = list(train_dataset.take(1))[0]\n",
    "\n",
    "# Check the shapes\n",
    "print(f\"image batch shape: {image_batch.shape}\")\n",
    "print(f\"label batch shape: {label_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Visualize a few samples\n",
    "# for i in range(5):  # Display the first 5 images in the batch\n",
    "#     plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(f\"Label: {label_batch[i]}\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_grid(images, labels, class_names, rows=2, cols=4):\n",
    "    \"\"\"\n",
    "    Plot a tight grid of randomly selected images with their labels.\n",
    "\n",
    "    Args:\n",
    "        images (numpy.ndarray): Batch of images to display.\n",
    "        labels (numpy.ndarray): Corresponding labels.\n",
    "        class_names (list): Class names for labels.\n",
    "        rows (int): Number of rows in the grid.\n",
    "        cols (int): Number of columns in the grid.\n",
    "    \"\"\"\n",
    "    # Shuffle the indices\n",
    "    indices = np.random.permutation(len(images))\n",
    "    selected_images = images[indices[: rows * cols]]\n",
    "    selected_labels = labels[indices[: rows * cols]]\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    fig.tight_layout(pad=1.0)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i >= len(selected_images):\n",
    "            break\n",
    "        ax.imshow(selected_images[i].astype(\"uint8\"))\n",
    "        ax.set_title(f\"Label: {class_names[selected_labels[i]]}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Convert tensors to numpy arrays for visualization\n",
    "image_batch_np = image_batch.numpy()\n",
    "label_batch_np = label_batch.numpy()\n",
    "\n",
    "# Class names for labels\n",
    "class_names = [\"charts\", \"non_charts\"]\n",
    "\n",
    "# Plot the grid\n",
    "plot_image_grid(image_batch_np, label_batch_np, class_names, rows=2, cols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_batch[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the range of values\n",
    "print(f\"max value: {np.max(image_batch[0].numpy())}\")\n",
    "print(f\"min value: {np.min(image_batch[0].numpy())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale_layer = tf.keras.layers.Rescaling(scale=1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_scaled = rescale_layer(image_batch[20]).numpy()\n",
    "\n",
    "print(image_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"max value: {np.max(image_scaled)}\")\n",
    "print(f\"min value: {np.min(image_scaled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Normalize a tf.data.Dataset using a Rescaling layer.\n",
    "    Args:\n",
    "        dataset: The tf.data.Dataset to normalize.\n",
    "    Returns:\n",
    "        A normalized tf.data.Dataset.\n",
    "    \"\"\"\n",
    "    return dataset.map(\n",
    "        lambda image, label: (rescale_layer(image), label),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# Normalize datasets\n",
    "train_dataset_scaled = normalize_dataset(train_dataset)\n",
    "val_dataset_scaled = normalize_dataset(val_dataset)\n",
    "test_dataset_scaled = normalize_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch of data\n",
    "sample_batch = list(train_dataset_scaled.take(1))[0]\n",
    "\n",
    "# Get the image\n",
    "image_scaled = sample_batch[0][10].numpy()\n",
    "\n",
    "# Check the range of values for this image\n",
    "print(f\"max value: {np.max(image_scaled)}\")\n",
    "print(f\"min value: {np.min(image_scaled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, model_file_name = create_model(\"mobile\")\n",
    "# model, model_file_name = create_model(\"custom-1\")\n",
    "# model, model_file_name = create_model(\"resnet\")\n",
    "# model, model_file_name = create_model(\"efficientnet\")\n",
    "# model, model_file_name = create_model(\"densenet\")\n",
    "model, model_file_name = create_model(\"mobile_large\")\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset_final = (\n",
    "    train_dataset_scaled.cache()\n",
    "    .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "    .prefetch(PREFETCH_BUFFER_SIZE)\n",
    ")\n",
    "\n",
    "# Configure the validation dataset\n",
    "validation_dataset_final = val_dataset_scaled.cache().prefetch(\n",
    "    PREFETCH_BUFFER_SIZE\n",
    ")\n",
    "\n",
    "# Configure the test dataset\n",
    "test_dataset_final = test_dataset_scaled.cache().prefetch(PREFETCH_BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_file_name,\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset_final,\n",
    "    validation_data=validation_dataset_final,\n",
    "    epochs=20,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True), save_checkpoint],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model --  See save_checkpoint\n",
    "# model.save(model_file_name)\n",
    "\n",
    "# model.export(\"../models/mobilenetv3_classifier_serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracies for each epoch\n",
    "\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, \"r\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy, test_auc = model.evaluate(test_dataset_final)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test AUC: {test_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the widget and take care of the display\n",
    "uploader = widgets.FileUpload(accept=\"image/*\", multiple=True)\n",
    "display(uploader)\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "\n",
    "\n",
    "def file_predict(filename, file, out):\n",
    "    \"\"\"A function for creating the prediction and printing the output.\"\"\"\n",
    "    image = tf.keras.utils.load_img(file, target_size=IMG_SIZE)\n",
    "    image = tf.keras.utils.img_to_array(image)\n",
    "    image = rescale_layer(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    prediction = model.predict(image, verbose=0)[0][0]\n",
    "\n",
    "    with out:\n",
    "        if prediction <= 0.5:\n",
    "            print(filename + \" is a chart\")\n",
    "        else:\n",
    "            print(filename + \" is not a chart\")\n",
    "\n",
    "\n",
    "def on_upload_change(change):\n",
    "    \"\"\"A function for geting files from the widget and running the prediction.\"\"\"\n",
    "    # Get the newly uploaded file(s)\n",
    "\n",
    "    items = change.new\n",
    "    for item in items:  # Loop if there is more than one file uploaded\n",
    "        file_jpgdata = BytesIO(item.content)\n",
    "        file_predict(item.name, file_jpgdata, out)\n",
    "\n",
    "\n",
    "# Run the interactive widget\n",
    "# Note: it may take a bit after you select the image to upload and process before you see the output.\n",
    "uploader.observe(on_upload_change, names=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown the kernel to free up resources.\n",
    "# Note: You can expect a pop-up when you run this cell. You can safely ignore that and just press `Ok`.\n",
    "\n",
    "# from IPython import get_ipython\n",
    "\n",
    "# k = get_ipython().kernel\n",
    "\n",
    "# k.do_shutdown(restart=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
